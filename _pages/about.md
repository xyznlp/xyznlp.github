---
permalink: /
title: "Short Bio"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a senior researcher at DXM AI Lab. Previously, I obtained my master’s degree from Beijing Normal University. I was also an intern at Microsoft Research Asia, Microsoft Xiaoice, Tencent Wechat and 360 Search. I am broadly interested in **Natural Language Processing** (Question Answering, Machine Reading Comprehension, Semantic Parsing, Generation), **Recommendation System** (Sequential Recommendation, User Modeling), **Information Retrieval** and **Multi-Modal** (Vision & Language), etc.
<!-- \[E-mail: xyz (-at~) mail.bnu.edu.cn\] --> 

News
======
- February 2021: Our team "Xuanyu Zhang - AI-Lab, DXM" won the championship at the leaderboard of **MS MARCO Document Ranking**. The model "DML" achieves 0.416 MRR on the eval set, which has been greatly improved compared with the previous model. [\[Tweet from MS MARCO\]](https://twitter.com/MSMarcoAI/status/1359965315875155976)
- February 2021: One paper on recommendation got accepted to **WWW'21 companion**.
- July 2021: One paper on multi-modal got accepted to **ACM MM'21**.
- August 2021: One paper on ranking got accepted to **CIKM'21**.
- December 2021: We won the championship at the classification leaderboard of **CLUE** (Chinese Language Understanding Evaluation Benchmark) with our proposed XuanYuan PLM. [\[CLUE Benchmark\]](https://www.cluebenchmarks.com/classification.html)
- December 2021: Our XuanYuan model, based on standard pipeline, surpassed other PLMs at the leaderboard of **KgCLUE** (Large-scale Knowledge Graph based QA Benchmark) on Dec 15, 2021.
- April 2022: We won the championship at the **ogbl-wikikg2** leaderboard with our proposed **TranS** model. [\[Leaderboard\]](https://ogb.stanford.edu/docs/leader_linkprop/#ogbl-wikikg2) [\[Paper\]](https://arxiv.org/abs/2204.08401) [\[Code\]](https://github.com/xyznlp/TranS)
- August 2022: One full paper on recommendation got accepted to **CIKM'22**.
- October 2022: Two papers on knowledge graph and prompt learning got accepted to findings of **EMNLP'22**.
- May 2023: One paper on long-sequence Transformer got accepted to findings of **ACL'23**.
- May 2023: We open-sourced **XuanYuan 2.0**, the first Chinese financial chat model with hundreds of billions parameters. [\[Huggingface\]](https://huggingface.co/xyz-nlp/XuanYuan2.0)
- August 2023: One paper on large language models got accepted to **CIKM'23**.
- August 2023: We won the **outstanding** paper award at **IJCAI—FinLLM'23**.
<!-- - January 2021: I served as a reviewer for ACL'21. -->
<!-- <font color="red"> </font> -->


Publications & Competitions
======
[\[Publications & Competitions\]](https://xyznlp.github.io/publications/)

Awards
======
- National Scholarship
- Huawei Scholarship
- Outstanding Graduate in Beijing
- Outstanding Graduate in Beijing Normal University 
- China Youth Scientific and Technological Innovation Award (Xiaoping Deng Award)

Community Service
======
- SPC/PC/Reviewer: ACL, EMNLP, NLPCC, AAAI, CIKM, IEEE TNNLS, ARR (ACL Rolling Review)
- Student Volunteer: ACL 2019
 <!-- (IEEE Transactions on Neural Networks and Learning Systems) --> 
